---
title: "Final Assignment, Task 3"
author: "Somtochukwu Nnajide"
date: "2023-04-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

Please run this chunk if necessary
```{r}
# please install packages if necessary 

# install.packages("GGally")
# install.packages("ellipse")
# install.packages("glue")
# install.packages("Metrics")
```

Please run this chunk
```{r}
#load necessary libraries

library(tidyverse)
library(GGally)
library(ellipse)
library(Metrics)

```

Please run this chunk
```{r}
#load master file

masterDf = read_csv("masterFile.csv")

```


# Task 3: Data-Driven Modelling: 	(15 marks)

1. Based on the covid19_data dataframe, that you have wrangled and used in the previous tasks, create a separate dataframe named "cor_data" with the data of these variables (CumCases, CumTests, Population, GDP, GDPCapita) variables.

    [Hint: you can use select function on the covid19_data dataframe]

```{r}
# The code and code description of this component go below here

cor_data <- masterDf %>% select(CumCases, CumTests, Population, GDP, GDPCapita)

cor_data

```

2. Compute the correlation matrix between the variables of the “cor_data” and visualise this correlation matrix.

```{r}
# The code and code description of this component go below here

#compute correlation matrix
cor(cor_data)

#visualise correlation matrix
ggcorr(cor_data, label = TRUE, label_alpha = TRUE)

```

3. visualize the distribution of the cumulative cases in the cor_data with and without changing the scale of the x axis to log transformation.

```{r}
# The code and code description of this component go below here

#distribution with log x_axis scale
ggplot(cor_data, aes(CumCases)) +
  geom_histogram(aes(y = ..density..), fill = "aquamarine3") +
  geom_density(color = "red") +
  scale_x_log10(labels = function(x) format(x, scientific = FALSE))

#distribution without log x_axis scale
ggplot(cor_data, aes(CumCases)) +
  geom_histogram(aes(y = ..density..), fill = "aquamarine3") 

```

4. Divide the cor_data into training and testing, where training data represent 65% of the number of rows.

```{r}
# The code and code description of this component go below here

# Determine the number of rows in the cor_data dataset
total_rows <- nrow(cor_data)

# Calculate 65% of the total number of rows for training set
training_size <- round(0.65 * total_rows)

# Randomly select rows for the training set
set.seed(123)  # Set a seed for reproducibility
index <- sample(1:total_rows, size = training_size, replace = FALSE)
train <- cor_data[index, ]

# Assign the remaining rows to the testing set
test <- cor_data[-index, ]

train
test

```

### Pre-assumptions

```{r}
#normal distribution of response variable has already been plotted in question 3
#response variable follows normal distribution when x-axis is log transformed

# show box plot to all of the variables to check the outliers
box_plot_data <- cor_data %>% 
  gather()

box_plot <- ggplot(box_plot_data, mapping = aes(x = key, y = value, fill = key, colour = key)) +
  geom_boxplot() + 
  facet_wrap(~key, scale="free")

box_plot

```

5. Train a linear regression model to predict cumulative cases from the GDP of the countries. Then, evaluate this model on the test data and print the root mean square error value.

```{r}
# The code and code description of this component go below here

# build model1 between cumulative cases and GDP
model1 <- lm(CumCases ~ GDP , data = train)
print(model1)

# Validating Regression Coefficients and Models
summary(model1)

#Evaluation
test$PredictedCumCases1 <- predict(model1, test)
tail(test[ , c("CumCases", "PredictedCumCases1")])

# compute the residual mean square error (RMSE) as a way of evaluation
preds <-  test$PredictedCumCases1
actual <- test$CumCases

#root mean square error value
rmse(preds, actual)

```

6. Train another linear regression model to predict cumulative cases from all the other variables. Then, evaluate this model on the test data and print the root mean square error value.

```{r}
# The code and code description of this component go below here

# build model1 between cumulative cases and all other variables
model2 <- lm(CumCases ~ . , data = train)
print(model2)

# Validating Regression Coefficients and Models
summary(model2)

#Evaluation
test$PredictedCumCases2 <- predict(model2, test)
tail(test[ , c("CumCases", "PredictedCumCases1", "PredictedCumCases2")])

# compute the residual mean square error (RMSE) as a way of evaluation
preds <-  test$PredictedCumCases2
actual <- test$CumCases

#root mean square error value
rmse(preds, actual)

```

### Post assumptions
```{r}
# Visualise the distribution of the residuals for both of the models

ggplot(model1, aes(model1$residuals)) +
  geom_histogram(aes(y = ..density..), fill = "#C99800") +
  geom_density(color = "blue") +
  scale_x_log10(labels = function(x) format(x, scientific = FALSE))

ggplot(model2, aes(model2$residuals)) +
  geom_histogram(aes(y = ..density..), fill = "#00BCD8") +
  geom_density(color = "red") +
  scale_x_log10(labels = function(x) format(x, scientific = FALSE))

```

7. Interpret the two models and write a small report of highlighting the differences between using the two models. For example, in which cases we should use the first model and in which cases the second one is better to use.

**Interpretation goes below here**:

Model1:

a. The p-value of model1 is less than 0.05 hence the model is significant.
b. The r-squared and adjusted r-squared indicate that the explanatory variable can explain
approximately 16% of the variation in the response variable.
c. The rmse of model1 is 41623.89, therefore applicable use cases include broad trend analysis, resource allocation planning, comparative analysis etc.

Model2:

a. The p-value of model2 is less than 0.05 hence the model is significant.
b. The r-squared and adjusted r-squared indicate that the explanatory variable can explain
approximately 75% of the variation in the response variable.
c. The rmse of model2 is 19650.18, therefore applicable use cases include forecasting daily or weekly cases, analyzing the impact of variants, evaluating testing strategies, predicting hospitalisation rates etc

----

**Task 3 final Report**: Highlight the output (Description, graphs and statistics) that have been generated by writing and running the code of the above components. 

----

*** 